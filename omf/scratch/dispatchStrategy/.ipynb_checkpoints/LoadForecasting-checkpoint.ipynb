{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 24-Hour Load Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-15b9b4183853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmpld3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmpld3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_eng_float_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m from pandas.core.index import (Index, CategoricalIndex, Int64Index,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/groupby/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroupBy\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from pandas.core.groupby.generic import (  # noqa: F401\n\u001b[1;32m      3\u001b[0m     SeriesGroupBy, DataFrameGroupBy, PanelGroupBy)\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGrouper\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroupby\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlibgroupby\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'compat'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt, timedelta\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "%matplotlib inline\n",
    "\n",
    "load = pd.read_csv('data/load/NCENT.csv')\n",
    "weather = pd.read_csv('data/weather/NCENT.csv')\n",
    "load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First get everything into one large dataframe\n",
    "load | dt, day of week, hour of day, years since 2000, temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df = pd.DataFrame()\n",
    "l, t = [], []\n",
    "for column in load.columns:\n",
    "    l.append(list(load[column]))\n",
    "    t.append(list(weather[column]))\n",
    "# flatten\n",
    "lf = [i for s in l for i in s]\n",
    "tf = [i for s in t for i in s]\n",
    "\n",
    "large_df['load'] = lf\n",
    "large_df['tempc'] = tf\n",
    "\n",
    "# fix outliers\n",
    "large_df['tempc'].replace([-9999], np.nan, inplace=True)\n",
    "large_df['tempc'].ffill(inplace=True)\n",
    "large_df['load'].ffill(inplace=True)\n",
    "\n",
    "large_df['load_prev'] = large_df['load'].shift(24)\n",
    "large_df['load_prev'].bfill(inplace=True)\n",
    "\n",
    "d = []\n",
    "for i in range(2002, 2019):\n",
    "    d.append([(dt(i, 1, 1) + timedelta(hours=1)*x) for x in range(8760)]) \n",
    "large_df['dates'] = [i for s in d for i in s]\n",
    "\n",
    "large_df['day'] = large_df['dates'].dt.dayofweek # 0 is MONDAY!!!\n",
    "large_df['hour'] = large_df['dates'].dt.hour\n",
    "large_df['month'] = large_df['dates'].dt.month\n",
    "large_df['year'] = large_df['dates'].dt.year\n",
    "large_df.head()\n",
    "#large_df.to_csv('flatData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data from \\[-1, 1\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = large_df.drop(['dates'], axis=1)\n",
    "\n",
    "norm_df['yearSince2000'] = norm_df['year'] - 2000\n",
    "norm_df['years_n'] = (norm_df['yearSince2000'] - norm_df['yearSince2000'].mean()) / (norm_df['yearSince2000'].max() - norm_df['yearSince2000'].min())\n",
    "\n",
    "norm_df['load_prev_n'] = (norm_df['load_prev'] - norm_df['load_prev'].mean()) / (norm_df['load_prev'].max() - norm_df['load_prev'].min())\n",
    "norm_df['temp_n'] = (norm_df['tempc'] - norm_df['tempc'].mean()) / (norm_df['tempc'].max() - norm_df['tempc'].min())\n",
    "\n",
    "norm_df.drop(['load', 'tempc', 'year'], axis=1, inplace=True)\n",
    "\n",
    "norm_df['day'] += 1 # make Sunday 0\n",
    "norm_df.loc[norm_df['day'] == 7, 'day'] = 0\n",
    "\n",
    "norm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now turn into a binary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df = pd.DataFrame()\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    s = []\n",
    "    for i in range(0, len(l), n):\n",
    "         s.append(l[i:i + n])\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "l = list(large_df['load'])\n",
    "m = [i for i in chunks(l, 24)]\n",
    "s = [val for val in m for _ in range(24)]\n",
    "n = np.array(s)\n",
    "\n",
    "for i in range(24):\n",
    "    s = 'l' + str(i)\n",
    "    bin_df[s] = n[:, i]\n",
    "    bin_df[s] = (bin_df[s] - large_df['load'].mean()) / (large_df['load'].max() - large_df['load'].min())\n",
    "\n",
    "bin_df.head()\n",
    "\n",
    "# create month vector\n",
    "y = [('m' + str(i)) for i in range(12)]\n",
    "for i, m in enumerate(y):\n",
    "    bin_df[m] = (norm_df['month'] == i).astype(int)\n",
    "\n",
    "# create day of week vector\n",
    "w = ['S', 'M', 'T', 'W', 'R', 'F', 'A']\n",
    "for i, d in enumerate(w):\n",
    "    bin_df[d] = (norm_df['day'] == i).astype(int)\n",
    "\n",
    "# create hour of day vector\n",
    "d = [('h' + str(i)) for i in range(24)]\n",
    "for i, h in enumerate(d):\n",
    "    bin_df[h] = (norm_df['hour'] == i).astype(int)\n",
    "\n",
    "bin_df['years_n'] = norm_df['years_n']\n",
    "bin_df['temp_n'] = norm_df['temp_n']\n",
    "bin_df['load_prev_n'] = norm_df['load_prev_n']\n",
    "\n",
    "# for_csv = bin_df.copy()\n",
    "# for_csv['load'] = large_df['load']\n",
    "# for_csv.to_csv('data/ncent_ml_data.csv', index=False)\n",
    "\n",
    "print(len(bin_df))\n",
    "print(bin_df.columns)\n",
    "bin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_X = bin_df#.drop('load_prev_n', axis=1) # all rows, features only, no labels\n",
    "all_y = large_df['load'] #all rows, label only, no features\n",
    "\n",
    "X_train, y_train = all_X[:-8760], all_y[:-8760]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDRegressor(max_iter=10000, tol=1e-4)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = all_X[-8760:], all_y[-8760:]\n",
    "y_prediction = clf.predict(X_test)\n",
    "\n",
    "graph_df = pd.DataFrame()\n",
    "graph_df['test'] = y_test\n",
    "graph_df['predict'] = y_prediction\n",
    "graph_df.plot(figsize=(12, 3))\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df.groupby('month')['load'].quantile(.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = []\n",
    "large_df['dayOfYear'] = large_df['dates'].dt.dayofyear\n",
    "for month in range(1, 13):\n",
    "    test = large_df[large_df['month'] == month]\n",
    "    m.append(test.loc[test['load'].idxmax()]['dayOfYear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "nerc6 = {\n",
    "\t'Memorial Day': [\n",
    "\t\tdatetime.date(1990, 5, 28),\n",
    "\t\tdatetime.date(1991, 5, 27),\n",
    "\t\tdatetime.date(1992, 5, 25),\n",
    "\t\tdatetime.date(1993, 5, 31),\n",
    "\t\tdatetime.date(1994, 5, 30),\n",
    "\t\tdatetime.date(1995, 5, 29),\n",
    "\t\tdatetime.date(1996, 5, 27),\n",
    "\t\tdatetime.date(1997, 5, 26),\n",
    "\t\tdatetime.date(1998, 5, 25),\n",
    "\t\tdatetime.date(1999, 5, 31),\n",
    "\t\tdatetime.date(2000, 5, 29),\n",
    "\t\tdatetime.date(2001, 5, 28),\n",
    "\t\tdatetime.date(2002, 5, 27),\n",
    "\t\tdatetime.date(2003, 5, 26),\n",
    "\t\tdatetime.date(2004, 5, 31),\n",
    "\t\tdatetime.date(2005, 5, 30),\n",
    "\t\tdatetime.date(2006, 5, 29),\n",
    "\t\tdatetime.date(2007, 5, 28),\n",
    "\t\tdatetime.date(2008, 5, 26),\n",
    "\t\tdatetime.date(2009, 5, 25),\n",
    "\t\tdatetime.date(2010, 5, 31),\n",
    "\t\tdatetime.date(2011, 5, 30),\n",
    "\t\tdatetime.date(2012, 5, 28),\n",
    "\t\tdatetime.date(2013, 5, 27),\n",
    "\t\tdatetime.date(2014, 5, 26),\n",
    "\t\tdatetime.date(2015, 5, 25),\n",
    "\t\tdatetime.date(2016, 5, 30),\n",
    "\t\tdatetime.date(2017, 5, 29),\n",
    "\t\tdatetime.date(2018, 5, 28),\n",
    "\t\tdatetime.date(2019, 5, 27),\n",
    "\t\tdatetime.date(2020, 5, 25),\n",
    "\t\tdatetime.date(2021, 5, 31),\n",
    "\t\tdatetime.date(2022, 5, 30),\n",
    "\t\tdatetime.date(2023, 5, 29),\n",
    "\t\tdatetime.date(2024, 5, 27),\n",
    "\t],\n",
    " \t'Labor Day': [\n",
    "\t \tdatetime.date(1990, 9, 3),\n",
    "\t\tdatetime.date(1991, 9, 2),\n",
    "\t\tdatetime.date(1992, 9, 7),\n",
    "\t\tdatetime.date(1993, 9, 6),\n",
    "\t\tdatetime.date(1994, 9, 5),\n",
    "\t\tdatetime.date(1995, 9, 4),\n",
    "\t\tdatetime.date(1996, 9, 2),\n",
    "\t\tdatetime.date(1997, 9, 1),\n",
    "\t\tdatetime.date(1998, 9, 7),\n",
    "\t\tdatetime.date(1999, 9, 6),\n",
    "\t\tdatetime.date(2000, 9, 4),\n",
    "\t\tdatetime.date(2001, 9, 3),\n",
    "\t\tdatetime.date(2002, 9, 2),\n",
    "\t\tdatetime.date(2003, 9, 1),\n",
    "\t\tdatetime.date(2004, 9, 6),\n",
    "\t\tdatetime.date(2005, 9, 5),\n",
    "\t\tdatetime.date(2006, 9, 4),\n",
    "\t\tdatetime.date(2007, 9, 3),\n",
    "\t\tdatetime.date(2008, 9, 1),\n",
    "\t\tdatetime.date(2009, 9, 7),\n",
    "\t\tdatetime.date(2010, 9, 6),\n",
    "\t\tdatetime.date(2011, 9, 5),\n",
    "\t\tdatetime.date(2012, 9, 3),\n",
    "\t\tdatetime.date(2013, 9, 2),\n",
    "\t\tdatetime.date(2014, 9, 1),\n",
    "\t\tdatetime.date(2015, 9, 7),\n",
    "\t\tdatetime.date(2016, 9, 5),\n",
    "\t\tdatetime.date(2017, 9, 4),\n",
    "\t\tdatetime.date(2018, 9, 3),\n",
    "\t\tdatetime.date(2019, 9, 2),\n",
    "\t\tdatetime.date(2020, 9, 7),\n",
    "\t\tdatetime.date(2021, 9, 6),\n",
    "\t\tdatetime.date(2022, 9, 5),\n",
    "\t\tdatetime.date(2023, 9, 4),\n",
    "\t\tdatetime.date(2024, 9, 2),\n",
    "\t],\n",
    "\t'Thanksgiving': [\n",
    "\t\tdatetime.date(1990, 11, 22),\n",
    "\t\tdatetime.date(1991, 11, 28),\n",
    "\t\tdatetime.date(1992, 11, 26),\n",
    "\t\tdatetime.date(1993, 11, 25),\n",
    "\t\tdatetime.date(1994, 11, 24),\n",
    "\t\tdatetime.date(1995, 11, 23),\n",
    "\t\tdatetime.date(1996, 11, 28),\n",
    "\t\tdatetime.date(1997, 11, 27),\n",
    "\t\tdatetime.date(1998, 11, 26),\n",
    "\t\tdatetime.date(1999, 11, 25),\n",
    "\t\tdatetime.date(2000, 11, 23),\n",
    "\t\tdatetime.date(2001, 11, 22),\n",
    "\t\tdatetime.date(2002, 11, 28),\n",
    "\t\tdatetime.date(2003, 11, 27),\n",
    "\t\tdatetime.date(2004, 11, 25),\n",
    "\t\tdatetime.date(2005, 11, 24),\n",
    "\t\tdatetime.date(2006, 11, 23),\n",
    "\t\tdatetime.date(2007, 11, 22),\n",
    "\t\tdatetime.date(2008, 11, 27),\n",
    "\t\tdatetime.date(2009, 11, 26),\n",
    "\t\tdatetime.date(2010, 11, 25),\n",
    "\t\tdatetime.date(2011, 11, 24),\n",
    "\t\tdatetime.date(2012, 11, 22),\n",
    "\t\tdatetime.date(2013, 11, 28),\n",
    "\t\tdatetime.date(2014, 11, 27),\n",
    "\t\tdatetime.date(2015, 11, 26),\n",
    "\t\tdatetime.date(2016, 11, 24),\n",
    "\t\tdatetime.date(2017, 11, 23),\n",
    "\t\tdatetime.date(2018, 11, 22),\n",
    "\t\tdatetime.date(2019, 11, 28),\n",
    "\t\tdatetime.date(2020, 11, 26),\n",
    "\t\tdatetime.date(2021, 11, 25),\n",
    "\t\tdatetime.date(2022, 11, 24),\n",
    "\t\tdatetime.date(2023, 11, 23),\n",
    "\t\tdatetime.date(2024, 11, 28),\n",
    "\t],\n",
    " \t'Independence Day (Observed)': [\n",
    "\t \tdatetime.date(1992, 7, 3),\n",
    "\t\tdatetime.date(1993, 7, 5),\n",
    "\t\tdatetime.date(1998, 7, 3),\n",
    "\t\tdatetime.date(1999, 7, 5),\n",
    "\t\tdatetime.date(2004, 7, 5),\n",
    "\t\tdatetime.date(2009, 7, 3),\n",
    "\t\tdatetime.date(2010, 7, 5),\n",
    "\t\tdatetime.date(2015, 7, 3),\n",
    "\t\tdatetime.date(2020, 7, 3),\n",
    "\t\tdatetime.date(2021, 7, 5),\n",
    "\t],\n",
    "\t\"New Year's Day (Observed)\": [\n",
    "\t\tdatetime.date(1993, 12, 31),\n",
    "\t\tdatetime.date(1995, 1, 2),\n",
    "\t\tdatetime.date(1999, 12, 31),\n",
    "\t\tdatetime.date(2004, 12, 31),\n",
    "\t\tdatetime.date(2006, 1, 2),\n",
    "\t\tdatetime.date(2010, 12, 31),\n",
    "\t\tdatetime.date(2012, 1, 2),\n",
    "\t\tdatetime.date(2017, 1, 2),\n",
    "\t\tdatetime.date(2021, 12, 31),\n",
    "\t\tdatetime.date(2023, 1, 2),\n",
    "\t],\n",
    "\t'Christmas Day (Observed)': [\n",
    "\t\tdatetime.date(1993, 12, 24),\n",
    "\t\tdatetime.date(1994, 12, 26),\n",
    "\t\tdatetime.date(1999, 12, 24),\n",
    "\t\tdatetime.date(2004, 12, 24),\n",
    "\t\tdatetime.date(2005, 12, 26),\n",
    "\t\tdatetime.date(2010, 12, 24),\n",
    "\t\tdatetime.date(2011, 12, 26),\n",
    "\t\tdatetime.date(2016, 12, 26),\n",
    "\t\tdatetime.date(2021, 12, 24),\n",
    "\t\tdatetime.date(2022, 12, 26),\n",
    "\t]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
